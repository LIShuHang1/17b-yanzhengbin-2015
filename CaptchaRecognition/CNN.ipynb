{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def read_data():\n",
    "    reader = tf.TFRecordReader()\n",
    "    train_name = [\"train-0.tfrecords\", \"train-1.tfrecords\", \"train-2.tfrecords\", \"train-3.tfrecords\", \"train-4.tfrecords\", \"train-5.tfrecords\", \"train-6.tfrecords\", \"train-7.tfrecords\"]\n",
    "#     train_name = [\"validation.tfrecords\"]\n",
    "    xx = []\n",
    "    for i in train_name:\n",
    "        file = os.path.join(\"TFRecord/\",i)\n",
    "        xx.append(file)\n",
    "    filename_queue = tf.train.string_input_producer(xx)\n",
    "\n",
    "    _, serialized_example = reader.read(filename_queue)\n",
    "\n",
    "    features = tf.parse_single_example(\n",
    "            serialized_example,\n",
    "            features={\n",
    "            'image_raw': tf.FixedLenFeature([], tf.string),\n",
    "            'label': tf.FixedLenFeature([], tf.int64)\n",
    "        })\n",
    "    labels = tf.cast(features['label'], tf.int32)\n",
    "    images = tf.decode_raw(features['image_raw'], tf.uint8)\n",
    "    images = tf.reshape(images,[32,48])\n",
    "    \n",
    "\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        images_batch, labels_batch = tf.train.batch([images, labels],\n",
    "                                                            batch_size=256,\n",
    "                                                            capacity=500\n",
    "                                                            )\n",
    "        coord = tf.train.Coordinator()\n",
    "        threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "        image, label = sess.run([images_batch, labels_batch])\n",
    "        coord.request_stop()\n",
    "        coord.join(threads)\n",
    "    return images_batch, labels_batch\n",
    "        \n",
    "        \n",
    "def conv2d(x, W):\n",
    "    \"\"\"conv2d returns a 2d convolution layer with full stride.\"\"\"\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "    \"\"\"max_pool_2x2 downsamples a feature map by 2X.\"\"\"\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
    "                        strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "\n",
    "def avg_pool_2x2(x):\n",
    "    \"\"\"avg_pool_2x2 downsamples a feature map by 2X.\"\"\"\n",
    "    return tf.nn.avg_pool(x, ksize=[1, 2, 2, 1],\n",
    "                        strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "\n",
    "def weight_variable(shape):\n",
    "    \"\"\"weight_variable generates a weight variable of a given shape.\"\"\"\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "\n",
    "def bias_variable(shape):\n",
    "    \"\"\"bias_variable generates a bias variable of a given shape.\"\"\"\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "\n",
    "def deepnn(x):\n",
    "    # input\n",
    "    with tf.name_scope('reshape'):\n",
    "        x_image = tf.reshape(x, [-1, 32, 48, 1])\n",
    "    \n",
    "    # First convolutional layer\n",
    "    with tf.name_scope('conv1'):\n",
    "        W_conv1 = weight_variable([3, 7, 1, 32])\n",
    "        b_conv1 = bias_variable([32])\n",
    "        h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n",
    "        \n",
    "        W_conv2 = weight_variable([3, 7, 32, 48])\n",
    "        b_conv2 = bias_variable([48])\n",
    "        h_conv2 = tf.nn.relu(conv2d(h_conv1, W_conv2) + b_conv2)\n",
    "        \n",
    "\n",
    "    # Pooling layer - downsamples by 2X.\n",
    "    with tf.name_scope('pool1'):\n",
    "        h_pool1 = max_pool_2x2(h_conv2)\n",
    "        h_pool1 = tf.nn.dropout(h_pool1, keep_prob)\n",
    "        \n",
    "\n",
    "    # second convolutional layer\n",
    "    with tf.name_scope(\"conv2\"):\n",
    "        W_conv3 = weight_variable([3,3,48,64])\n",
    "        b_conv3 = bias_variable([64])\n",
    "        h_conv3 = tf.nn.relu(conv2d(h_pool1, W_conv3) + b_conv3)\n",
    "        \n",
    "        W_conv4 = weight_variable([3,3,64,72])\n",
    "        b_conv4 = bias_variable([72])\n",
    "        h_conv4 = tf.nn.relu(conv2d(h_conv3, W_conv4) + b_conv4)\n",
    "        \n",
    "    # max_pool\n",
    "    with tf.name_scope(\"pool2\"):\n",
    "        h_pool2 = avg_pool_2x2(h_conv4)\n",
    "        h_pool2 = tf.nn.dropout(h_pool2, keep_prob)\n",
    "        \n",
    "        \n",
    "    # third convolutional layer\n",
    "    with tf.name_scope(\"conv3\"):\n",
    "        W_conv5 = weight_variable([3,3,72,128])\n",
    "        b_conv5 = bias_variable([128])\n",
    "        h_conv5 = tf.nn.relu(conv2d(h_pool2, W_conv5) + b_conv5)\n",
    "        \n",
    "    # pool\n",
    "    with tf.name_scope(\"pool3\"):\n",
    "        h_pool3 = avg_pool_2x2(h_conv5)\n",
    "        h_pool3 = tf.nn.dropout(h_pool3, keep_prob)\n",
    "\n",
    "  # Fully connected layer 1 \n",
    "    with tf.name_scope('fc1'):\n",
    "        W_fc1 = weight_variable([4*6*128, 256])\n",
    "        b_fc1 = bias_variable([256])\n",
    "        \n",
    "        h_pool3_flat = tf.reshape(h_pool3, [-1, 4*6*128])\n",
    "        h_fc1 = tf.nn.relu(tf.matmul(h_pool3_flat, W_fc1) + b_fc1)\n",
    "    \n",
    "  # Dropout - controls the complexity of the model, prevents co-adaptation of features.\n",
    "    with tf.name_scope('dropout'):\n",
    "        h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "        \n",
    "        \n",
    "    # Fully connected layer 2    \n",
    "    with tf.name_scope('fc2'):\n",
    "        W_fc2 = weight_variable([256, 4*11])\n",
    "        b_fc2 = bias_variable([4*11])\n",
    "\n",
    "        y_conv = tf.matmul(h_fc1_drop, W_fc2) + b_fc2\n",
    "\n",
    "    return y_conv, keep_prob\n",
    "\n",
    "\n",
    "# Import data\n",
    "images_batch, labels_batch = read_data()\n",
    "\n",
    "# Create the model\n",
    "x = tf.placeholder(tf.float32, [None, 32, 48])\n",
    "\n",
    "# Define loss and optimizer\n",
    "y_ = tf.placeholder(tf.float32, [None, 4, 11])\n",
    "\n",
    "# keep_prob\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "def onhot(lab):\n",
    "    arr = np.zeros([256,4,11])\n",
    "    for a, b in enumerate(lab):\n",
    "        y = list(str(b))\n",
    "        for i in range(len(y)):\n",
    "            y[i] = int(y[i])\n",
    "        \n",
    "        for i in range(4):\n",
    "            if i < len(y):\n",
    "                arr[a,i,y[i]] = 1\n",
    "            else:\n",
    "                arr[a,i,10] = 1\n",
    "    return arr\n",
    "\n",
    "# Build the graph for the deep net\n",
    "y_conv, keep_prob = deepnn(x)\n",
    "\n",
    "yy = tf.reshape(y_conv,[-1,4,11])\n",
    "\n",
    "\n",
    "with tf.name_scope('loss'):\n",
    "    cross_entropy1 =  tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_[:,0],\n",
    "                                                        logits=yy[:,0]))\n",
    "    cross_entropy2 =  tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_[:,1],\n",
    "                                                        logits=yy[:,1]))\n",
    "    cross_entropy3 =  tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_[:,2],\n",
    "                                                        logits=yy[:,2]))\n",
    "    cross_entropy4 =  tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_[:,3],\n",
    "                                                        logits=yy[:,3]))\n",
    "    cross_entropy = (cross_entropy1 + cross_entropy2 + cross_entropy3 + cross_entropy4) / 4.\n",
    "    aa = tf.summary.scalar(\"loss\",cross_entropy)\n",
    "    \n",
    "\n",
    "with tf.name_scope('adam_optimizer'):\n",
    "    train_step = tf.train.AdamOptimizer().minimize(cross_entropy)\n",
    "\n",
    "with tf.name_scope('accuracy'):\n",
    "    #correct_prediction = [tf.equal(tf.argmax(tf.nn.softmax(yy[None, i]), 1), tf.argmax(y_[None, i], 1)) for i in range(4)]\n",
    "    correct_prediction = tf.equal(tf.argmax(tf.reshape(y_conv,[-1,4,11]), 2), tf.argmax(tf.reshape(y_, [-1,4,11]), 2))\n",
    "    correct_prediction = tf.cast(correct_prediction, tf.float32)\n",
    "    \n",
    "    accuracy = tf.reduce_mean(correct_prediction)\n",
    "\n",
    "ckpt_dir = \"./test_dir\"\n",
    "if not os.path.exists(ckpt_dir):\n",
    "    os.makedirs(ckpt_dir)\n",
    "# saver\n",
    "saver = tf.train.Saver()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./test_dir/model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from ./test_dir/model.ckpt\n",
      "epoch 0, loss is 0.0260106 validation accuracy 0.988281\n",
      "epoch 1, loss is 0.0180938 validation accuracy 0.996094\n",
      "epoch 2, loss is 0.0110382 validation accuracy 0.998047\n",
      "epoch 3, loss is 0.0158613 validation accuracy 0.994141\n",
      "epoch 4, loss is 0.0156227 validation accuracy 0.998047\n",
      "epoch 5, loss is 0.0182083 validation accuracy 0.994141\n",
      "epoch 6, loss is 0.0214361 validation accuracy 0.994141\n",
      "epoch 7, loss is 0.016967 validation accuracy 0.994141\n",
      "epoch 8, loss is 0.017105 validation accuracy 0.995117\n",
      "epoch 9, loss is 0.0179023 validation accuracy 0.99707\n",
      "epoch 10, loss is 0.0145826 validation accuracy 0.994141\n",
      "epoch 11, loss is 0.0128047 validation accuracy 0.998047\n",
      "epoch 12, loss is 0.0124751 validation accuracy 0.99707\n",
      "epoch 13, loss is 0.0163951 validation accuracy 0.99707\n",
      "epoch 14, loss is 0.00856568 validation accuracy 0.999023\n",
      "epoch 15, loss is 0.0138171 validation accuracy 0.995117\n",
      "epoch 16, loss is 0.025473 validation accuracy 0.993164\n",
      "epoch 17, loss is 0.0230673 validation accuracy 0.992188\n",
      "epoch 18, loss is 0.0154414 validation accuracy 0.995117\n",
      "epoch 19, loss is 0.0122402 validation accuracy 0.998047\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with tf.Session() as sess:\n",
    "    # 初始化变量\n",
    "    sess.run([tf.global_variables_initializer(), tf.local_variables_initializer()])\n",
    "    \n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "    \n",
    "    ckpt = tf.train.get_checkpoint_state(ckpt_dir)\n",
    "    if ckpt and ckpt.model_checkpoint_path:\n",
    "        print(ckpt.model_checkpoint_path)\n",
    "        saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "    \n",
    "    for epoch in range(20):\n",
    "        img, lab = sess.run([images_batch, labels_batch])\n",
    "        labe = onhot(lab)\n",
    "            \n",
    "        my_loss, _, accuracy_validation, pre = sess.run([cross_entropy, train_step, accuracy, yy], feed_dict={x: img / 255, y_: labe, keep_prob: 1})\n",
    "        \n",
    "#         for i in range(30):\n",
    "#             print(np.argmax(pre[i],1))\n",
    "#             print(np.argmax(labe[i],1))\n",
    "#             print(\"_____________________________________\")\n",
    "        \n",
    "        if epoch % 1 == 0:\n",
    "            print('epoch %d, loss is %g validation accuracy %g' % (\n",
    "                epoch,\n",
    "                float(my_loss),\n",
    "                float(accuracy_validation)))\n",
    "    coord.request_stop()\n",
    "    coord.join(threads)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./test_dir/model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from ./test_dir/model.ckpt\n",
      "epoch 0, loss is 0.143894 validation accuracy 0.946289\n",
      "epoch 50, loss is 0.121993 validation accuracy 0.956055\n",
      "epoch 100, loss is 0.124289 validation accuracy 0.956055\n",
      "epoch 150, loss is 0.0916146 validation accuracy 0.967773\n",
      "epoch 200, loss is 0.144487 validation accuracy 0.948242\n",
      "epoch 250, loss is 0.169898 validation accuracy 0.942383\n",
      "epoch 300, loss is 0.103348 validation accuracy 0.960938\n",
      "epoch 350, loss is 0.113049 validation accuracy 0.957031\n",
      "epoch 400, loss is 0.158303 validation accuracy 0.947266\n",
      "epoch 450, loss is 0.11112 validation accuracy 0.963867\n",
      "epoch 500, loss is 0.112569 validation accuracy 0.958984\n",
      "epoch 550, loss is 0.0937502 validation accuracy 0.970703\n",
      "epoch 600, loss is 0.0923246 validation accuracy 0.96582\n",
      "epoch 650, loss is 0.118696 validation accuracy 0.954102\n",
      "epoch 700, loss is 0.112628 validation accuracy 0.957031\n",
      "epoch 750, loss is 0.0751323 validation accuracy 0.964844\n",
      "epoch 800, loss is 0.082496 validation accuracy 0.974609\n",
      "epoch 850, loss is 0.127389 validation accuracy 0.954102\n",
      "epoch 900, loss is 0.126995 validation accuracy 0.953125\n",
      "epoch 950, loss is 0.0807354 validation accuracy 0.970703\n",
      "epoch 1000, loss is 0.0781442 validation accuracy 0.97168\n",
      "epoch 1050, loss is 0.0762332 validation accuracy 0.969727\n",
      "epoch 1100, loss is 0.0767756 validation accuracy 0.973633\n",
      "epoch 1150, loss is 0.0899923 validation accuracy 0.97168\n",
      "epoch 1200, loss is 0.0772935 validation accuracy 0.970703\n",
      "epoch 1250, loss is 0.0783499 validation accuracy 0.972656\n",
      "epoch 1300, loss is 0.0969156 validation accuracy 0.96582\n",
      "epoch 1350, loss is 0.0942734 validation accuracy 0.96582\n",
      "epoch 1400, loss is 0.077398 validation accuracy 0.967773\n",
      "epoch 1450, loss is 0.076642 validation accuracy 0.972656\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    # 初始化变量\n",
    "    sess.run([tf.global_variables_initializer(), tf.local_variables_initializer()])\n",
    "    # tensorboard\n",
    "    writer = tf.summary.FileWriter('graph', sess.graph)\n",
    "    merged = tf.summary.merge([aa])\n",
    "    \n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "    ckpt = tf.train.get_checkpoint_state(ckpt_dir)\n",
    "    if ckpt and ckpt.model_checkpoint_path:\n",
    "        print(ckpt.model_checkpoint_path)\n",
    "        saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "    \n",
    "    for epoch in range(1500):\n",
    "        img, lab = sess.run([images_batch, labels_batch])\n",
    "        labe = onhot(lab)\n",
    "        \n",
    "#         %matplotlib inline\n",
    "#         import matplotlib.pyplot as plt\n",
    "#         plt.imshow(img[0].reshape([32, 48]))\n",
    "#         print(lab[0])\n",
    "#         print(labe[0])\n",
    "#         break\n",
    "\n",
    "        my_loss, _, accuracy_validation, summary = sess.run([cross_entropy, train_step, accuracy, merged], feed_dict={x: img / 255., y_: labe, keep_prob: 0.75})\n",
    "        \n",
    "        writer.add_summary(summary,epoch)\n",
    "        \n",
    "        if epoch % 50 == 0:\n",
    "            saver.save(sess,ckpt_dir + \"/model.ckpt\")\n",
    "            print('epoch %d, loss is %g validation accuracy %g' % (\n",
    "                epoch,\n",
    "                float(my_loss),\n",
    "                float(accuracy_validation)))\n",
    "            \n",
    "    coord.request_stop()\n",
    "    coord.join(threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./test_dir/model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from ./test_dir/model.ckpt\n",
      "[[[ 6  6  7 10]\n",
      "  [ 6  8  3 10]\n",
      "  [ 8  3  8  4]]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "a = os.listdir(\"./image\")\n",
    "data = []\n",
    "for i,j in enumerate(a):\n",
    "    files_name = os.path.join(\"./image\",j)\n",
    "    a_image = Image.open(files_name).convert('L')\n",
    "    changed_image = a_image.resize((48,32),Image.ANTIALIAS)\n",
    "    image_raw = np.array(changed_image)\n",
    "#     plt.imshow(image_raw,cmap=\"gray\")\n",
    "#     plt.show()\n",
    "    data.append(image_raw/255.)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # 初始化变量\n",
    "    sess.run([tf.global_variables_initializer(), tf.local_variables_initializer()])\n",
    "    \n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "    \n",
    "    ckpt = tf.train.get_checkpoint_state(ckpt_dir)\n",
    "    if ckpt and ckpt.model_checkpoint_path:\n",
    "        print(ckpt.model_checkpoint_path)\n",
    "        saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "    output = sess.run([yy],feed_dict = {x:data, keep_prob:1})\n",
    "    print(np.argmax(output,3))\n",
    "    with open(\"data/yanzhengbin.txt\",\"w\") as f:\n",
    "        for i in range(len(output)):\n",
    "            f.write(str(np.argmax(output, 3)[i])+'\\n')\n",
    "    coord.request_stop()\n",
    "    coord.join(threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[[ 6  6  7 10]\\n', ' [ 6  8  3 10]\\n', ' [ 8  3  8  4]]\\n']\n"
     ]
    }
   ],
   "source": [
    "with open(\"data/yanzhengbin.txt\",\"rt\") as f:\n",
    "        x = f.readlines()\n",
    "        print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
